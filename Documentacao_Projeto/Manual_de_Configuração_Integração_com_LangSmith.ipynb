{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual de Configuração Integração com LangSmith\n",
    "\n",
    "**Autor(a)** Debora da Costa Medeiros\n",
    "\n",
    "**Contato:** `[debora.medeiros@icomp.ufam.edu.br]`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Descrição Geral\n",
    "\n",
    "Este documento descreve o processo de integração de um agente de IA baseado em LLM com o LangSmith, com o objetivo de monitorar, depurar e avaliar seu desempenho. O projeto inclui o estudo da documentação oficial do LangSmith, configuração do ambiente, criação de um exemplo funcional e análise de métricas como custo, latência e qualidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Objetivos\n",
    "- Explorar e entender a documentação oficial do LangSmith.\n",
    "- Configurar o ambiente para integração.\n",
    "- Criar um exemplo funcional de agente de IA integrado ao LangSmith.\n",
    "- Monitorar e capturar métricas relevantes do agente (entradas, saídas, erros, desempenho).\n",
    "- Realizar testes para avaliar a qualidade dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução ao LangSmith\n",
    "\n",
    "O **LangSmith** é uma plataforma projetada para facilitar a integração, o monitoramento e a avaliação de agentes de IA baseados em modelos de linguagem (LLMs). Ele oferece ferramentas para rastrear entradas, saídas, erros e métricas de desempenho, permitindo aos desenvolvedores otimizar seus agentes de forma mais eficaz e informada.\n",
    "\n",
    "Principais Recursos\n",
    "1. Monitoramento em Tempo Real\n",
    "\n",
    "- Acompanha métricas como custo, latência e qualidade diretamente pela interface da plataforma.\n",
    "\n",
    "2. Depuração Detalhada\n",
    "\n",
    "- Mostra logs e fluxos de interação para identificar problemas ou melhorar o comportamento do agente.\n",
    "\n",
    "3. Análise de Desempenho\n",
    "\n",
    "- Permite a comparação com diferentes versões do agente, permitindo avaliar resultados e tomar decisões com base em dados concretos.\n",
    "\n",
    "4. Integração Simples com LLMs\n",
    "\n",
    "- Compatível com bibliotecas como LangChain e modelos populares, incluindo OpenAI e outros provedores de LLMs.\n",
    "\n",
    "5. Escalabilidade\n",
    "\n",
    "- Ideal para projetos pequenos e grandes, permitindo o uso eficiente em aplicações de produção.\n",
    "\n",
    "#### Benefícios\n",
    "\n",
    "- **Melhorias Contínuas**: Permite identificar áreas de melhoria no desempenho do agente com base em métricas detalhadas.\n",
    "\n",
    "- **Economia de Recursos**: Permite rastreiar e reduzir custos de execução ao analisar a eficiência do agente.\n",
    "\n",
    "- **Foco em Resultados**: Possibilita que se Dedique mais tempo ao desenvolvimento estratégico, com ferramentas que simplificam a depuração e o monitoramento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configuração do Ambiente\n",
    "- 3.1 Requisitos\n",
    "   - Linguagem de Programação: Python (versão 3.12.7)\n",
    "   - Bibliotecas Necessárias:\n",
    "   - langchain\n",
    "   - langsmith\n",
    "   - openai (ou outra LLM que estiver sendo utilizada)\n",
    "\n",
    "- 3.2 Instalação das Dependências\n",
    "   - Execute o seguinte comando para instalar as bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip3 install -U langsmith openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3.3 Configuração da API\n",
    "\n",
    "No terminal configure as seguinte variáveis de ambiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "export LANGCHAIN_TRACING_V2=true\n",
    "export LANGCHAIN_API_KEY=\"sua_chave_de_api_aqui\"\n",
    "export OPENAI_API_KEY=\"sua_chave_de_api_aqui\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **LANGCHAIN_TRACING_V2=true**  ativa o rastreamento global do LangSmith. Com essa configuração ativa, qualquer script que utilize a biblioteca LangChain automaticamente será rastreado, independentemente se for usado ou não explicitamente o wrappers.wrap_openai ou o decorador @traceable no código.\n",
    "\n",
    "Para conseguir a chave de API do LangChain para LangSmith é preciso acessar o LangSmith em https://www.langchain.com/langsmith e:\n",
    "- Fazer login com uma conta (pode ser via GitHub ou email).\n",
    "- Na lateral esquerda procurar por Settings (Configurações).\n",
    "- Em API Keys, clicar em Create New Key.\n",
    "- Copiar a chave gerada — ela será usada para autenticar as chamadas na biblioteca LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fins de teste crie o seguinte script python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import wrappers, traceable\n",
    "\n",
    "# Auto-trace LLM calls in-context\n",
    "client = wrappers.wrap_openai(openai.Client())\n",
    "\n",
    "@traceable # Auto-trace this function\n",
    "def pipeline(user_input: str):\n",
    "    result = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "        model=\"gpt-4o-mini\"\n",
    "    )\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "pipeline(\"Hello, world!\")\n",
    "# Out:  Hello there! How can I assist you today?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicação do script\n",
    "\n",
    "- `[openai]`: biblioteca oficial para acessar modelos de linguagem da OpenAI, como o GPT.\n",
    "- `[langsmith.wrappers]`: fornece a funcionalidade para envolver (`[wrap]`) o cliente da OpenAI com suporte ao rastreamento.\n",
    "- `[langsmith.traceable]`: decorador que permite rastrear automaticamente a execução de funções específicas.\n",
    "\n",
    "- `[client = wrappers.wrap_openai(openai.Client())]`: A função `[wrappers.wrap_openai]` envolve o cliente da OpenAI (`[openai.Client()]`) com funcionalidades de rastreamento, permitindo que todas as chamadas realizadas por meio dele sejam automaticamente registradas pelo LangSmith.\n",
    "\n",
    "- O rastreamento captura detalhes como a entrada do usuário, o modelo usado, a saída gerada e o tempo de execução.\n",
    "\n",
    "- Quando a função `[pipeline]` é executada o decorador `[@traceable]` registra automaticamente a sua execução e coleta informações como:\n",
    "     - Argumentos de entrada (User Input);\n",
    "     - Saída da função (Output);\n",
    "     - Hora de início (End Time)\n",
    "     - Hora do Fim (End Time)\n",
    "     - Tempo para o primeiro token (Time to First Token)\n",
    "     - Status (Sucesso ou Falha)\n",
    "     - Total tokens\n",
    "     - Latência\n",
    "\n",
    "- O `[client.chat.completions.create]` envia uma solicitação ao modelo de linguagem com o prompt fornecido em `[user_input]`\n",
    "     - `[messages]`: contém uma lista de mensagens no formato necessário para os modelos de chat da OpenAI. Aqui, há apenas uma mensagem com o papel de `[\"user\"]` e o conteúdo fornecido pelo usuário.\n",
    "     - `[model=\"gpt-4o-mini\"]`: especifica o modelo de linguagem que será usado. Neste caso é o`[\"gpt-4o-mini\"]`.\n",
    "\n",
    "- `[pipeline(\"Hello, world!\")]` é a chamada da função que envia a mensagem `[\"Hello, world!]` ao modelo.\n",
    "\n",
    "- A saída `[\"Hello there! How can I assist you today?\"]` é um exemplo de resposta gerada pelo modelo.\n",
    "\n",
    "- Como a função está decorada com @traceable, toda a execução é registrada automaticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a execução do script é possível ver as medidas feitas pelo LangSmith no endereço https://www.langchain.com/langsmith. Após realizar o login, basta clicar em `default` no campo `Tracing Projects`. Uma página com informações diversas da execução aparecerá como segue na imegme que segue: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Captura de Tela](imagens/Captura_de_tela_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se necessário utilizar uma versão autônoma do LangSmith por questões de privacidade ou segurança, deve se definir o LANGSMITH_ENDPOINT com a URL da instância que está hospedando. Logo a configuração inicila deve ser como segue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "export LANGSMITH_ENDPOINT=\"http://localhost:8000\"\n",
    "export LANGCHAIN_TRACING_V2=true\n",
    "export LANGCHAIN_API_KEY=\"sua_chave_de_api_aqui\"\n",
    "export OPENAI_API_KEY=\"sua_chave_de_api_aqui\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utizando o **LANGSMITH_ENDPOINT** o LangChain passa a enviar os dados de rastreamento (como prompts, respostas, tempos de execução, etc.) para o endpoint especificado e não mais para o o endpoint padrão da LangChain na nuvem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fontes e Recursos\n",
    "\n",
    "- **Documentação Oficial do LangSmith**: [Documentação Oficial do LangSmith](https://docs.smith.langchain.com/)\n",
    "\n",
    "- **Repositório no GitHub**: [Repositório no GitHub](https://github.com/langchain-ai/langsmith-sdk)\n",
    "\n",
    "- **Artigo Introdutório ao LangSmith (Medium)**: [Artigo Introdutório ao LangSmith](https://medium.com/dataherald/cutting-llm-costs-by-83-with-langsmith-e44bb63af2a8)\n",
    "\n",
    "- **Comunidade no Discord**: [Comunidade no Discord](https://discord.gg/langchain)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
